{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.dataset import get_loader, calculate_hash\n",
    "from networks.model import MyModel\n",
    "from utils.neptune import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration from json file. Alternatively you can put your configuration here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     \"neptune\": {\n",
    "#         \"project_name\": \"inn/Hippocampus\"\n",
    "#     },\n",
    "#     \"setup\": {\n",
    "#         \"dataset_dir\": \"/home/paperspace/datasets/processed/hippocampus_coronal_mindboggle_176x256_inn\",\n",
    "#         \"checkpoint_dir\": \"output/models\",\n",
    "#         \"struct\": \"hippocampus\",\n",
    "#         \"epochs\": 100,\n",
    "#         \"batch_size\": 16,\n",
    "#         \"train_ds_limit\": None,\n",
    "#         \"valid_ds_limit\": None,\n",
    "#         \"input_shape\": [\n",
    "#             256,\n",
    "#             176\n",
    "#         ],\n",
    "#         \"augment\": True,\n",
    "#         \"seed\": 5\n",
    "#     },\n",
    "#     \"model\": {\n",
    "#             \"arch\": \"Unet\",\n",
    "#             \"filters\": 16,\n",
    "#             \"loss_fn\": \"boundary_gdl\",\n",
    "#             \"optimizer_fn\": \"RAdam\",\n",
    "#             \"checkpoint\": \"hippocampus_coronal_boundary_gdl_unet_aug_radam\"\n",
    "#     },\n",
    "#     \"tags\": ['hippocampus', 'coronal']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neptune.config.json', 'r') as cfg_file:\n",
    "    config = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = config['setup']\n",
    "model = config['model']\n",
    "tags = config['tags'] or []\n",
    "dataset_dir = setup['dataset_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(dataset_dir, 'train',\n",
    "                          augment=setup['augment'],\n",
    "                          shuffle=True,\n",
    "                          limit=setup['train_ds_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get validation dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = get_loader(dataset_dir, 'valid',\n",
    "                          limit=setup['valid_ds_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate training dataset md5 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset train hash...\n",
      "Calculated hash: c52a048535618ec3eea25a5b366cac34\n"
     ]
    }
   ],
   "source": [
    "train_hash = calculate_hash(dataset_dir, 'train', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate training dataset md5 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset valid hash...\n",
      "Calculated hash: e7322acff870f4c7367f5e9906b0af22\n"
     ]
    }
   ],
   "source": [
    "valid_hash = calculate_hash(dataset_dir, 'valid', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune.ai configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(inn/Hippocampus)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.init(config['neptune']['project_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune.ai experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab model hyperparameters\n",
    "You can save any parameter you like, just append it to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'arch': model['arch'],\n",
    "    'batch_size': setup['batch_size'],\n",
    "    'filters': model['filters'],\n",
    "    'loss_fn': model['loss_fn'],\n",
    "    'optimizer_fn': model['optimizer_fn'],\n",
    "    'data_augment': setup['augment'],\n",
    "    'seed': setup['seed'],\n",
    "    'train_data_version': train_hash,\n",
    "    'valid_data_version': valid_hash\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/inn/Hippocampus/e/HIP-31\n"
     ]
    }
   ],
   "source": [
    "experiment = neptune.create_experiment(name=setup['struct'], params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add experiment tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.append_tag(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Save dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_text('train_data_version', train_hash)\n",
    "experiment.log_text('valid_data_version', valid_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
=======
>>>>>>> master
    "# Training loop\n",
    "Basically this is the place, where we integrate neptune.ai with our codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyModel(checkpoint_dir=setup['checkpoint_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.setup_model(\n",
    "    train_generator=train_loader,\n",
    "    valid_generator=valid_loader,\n",
    "    checkpoint=model['checkpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 176, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 176, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 176, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 176, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 176, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 176, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 176, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 88, 16)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 88, 32)  4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 88, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 88, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 88, 32)  9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 88, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 88, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 44, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 44, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 44, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 44, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 44, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 44, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 44, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 22, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 22, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 22, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 22, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 22, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 22, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 22, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 11, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 11, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 11, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 11, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 11, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 11, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 11, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 22, 128)  295040      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 22, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 22, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 22, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 22, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 22, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 22, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 22, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 44, 64)   73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 44, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 44, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 44, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 44, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 44, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 44, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 44, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 88, 32)  18464       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 88, 64)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 88, 32)  18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 88, 32)  128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 88, 32)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 88, 32)  9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 88, 32)  128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 88, 32)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 176, 16) 4624        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 176, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 176, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 176, 16) 64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 176, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 176, 16) 2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 176, 16) 64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 176, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 176, 1)  17          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,164,305\n",
      "Trainable params: 2,161,361\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.create_model(arch=model['arch'],\n",
    "                      optimizer_fn=model['optimizer_fn'],\n",
    "                      loss_fn=model['loss_fn'],\n",
    "                      n_filters=model['filters'],\n",
    "                      input_shape=tuple(setup['input_shape']),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neptune Callback for training\n",
    "We are using Tensorflow 2.0 with Keras helpers, so we can make use of Callbacks to save monitored metrics during the training. Each epoch restult metrics will be saved as chart log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "                                                \n",
      "Epoch 00001: val_loss improved from inf to 0.99397, saving model to output/models/hippocampus_coronal_boundary_gdl_unet_aug_adam.h5\n",
      "Train loss: 0.99022, accuracy: 82.07%\n",
      "Validation loss: 0.99397, accuracy: 99.70%\n",
      "weighted_dice: 0.008020839653909206\n",
      "\n",
      "Epoch time: 44.93s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 2 / 10\n",
      "                                                \n",
      "Epoch 00002: val_loss did not improve from 0.99397\n",
      "Train loss: 1.44226, accuracy: 91.76%\n",
      "Validation loss: 2.95177, accuracy: 74.36%\n",
      "weighted_dice: 0.010443873703479767\n",
      "\n",
      "Epoch time: 45.44s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 3 / 10\n",
      "                                                \n",
      "Epoch 00003: val_loss did not improve from 0.99397\n",
      "Train loss: 1.60262, accuracy: 94.91%\n",
      "Validation loss: 8.78126, accuracy: 10.45%\n",
      "weighted_dice: 0.007021597120910883\n",
      "\n",
      "Epoch time: 44.83s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 4 / 10\n",
      "                                                \n",
      "Epoch 00004: val_loss did not improve from 0.99397\n",
      "Train loss: 1.61659, accuracy: 96.61%\n",
      "Validation loss: 8.53707, accuracy: 54.15%\n",
      "weighted_dice: 0.004214376211166382\n",
      "\n",
      "Epoch time: 45.05s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 5 / 10\n",
      "                                                \n",
      "Epoch 00005: val_loss did not improve from 0.99397\n",
      "Train loss: 1.53603, accuracy: 97.46%\n",
      "Validation loss: 16.22356, accuracy: 10.92%\n",
      "weighted_dice: 0.005257537588477135\n",
      "\n",
      "Epoch time: 45.89s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 6 / 10\n",
      "                                                \n",
      "Epoch 00006: val_loss did not improve from 0.99397\n",
      "Train loss: 1.44944, accuracy: 97.51%\n",
      "Validation loss: 14.76125, accuracy: 51.77%\n",
      "weighted_dice: 0.006050191354006529\n",
      "\n",
      "Epoch time: 46.52s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 7 / 10\n",
      "                                                \n",
      "Epoch 00007: val_loss did not improve from 0.99397\n",
      "Train loss: 1.29896, accuracy: 98.30%\n",
      "Validation loss: 21.89587, accuracy: 24.96%\n",
      "weighted_dice: 0.008266931399703026\n",
      "\n",
      "Epoch time: 47.34s\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Epoch 8 / 10\n",
      "Train batch 6 / 16                     \r"
     ]
    }
   ],
   "source": [
    "my_model.start_train(epochs=setup['epochs'], custom_callbacks=[\n",
    "    NeptuneMonitor(experiment=experiment, evaluation=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.load_model(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neptune Callback for evaluation\n",
    "Similarily to training we are using callback to save metrics. This time we are doing it for model evaluation, so only final metrics will be saved, without epoch by epoch chart log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.start_evaluate(custom_callbacks=[\n",
    "    NeptuneMonitor(experiment=experiment, evaluation=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload saved model\n",
    "After training we are sending best saved model checkpoint, as specified in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_artifact(os.path.join(\n",
    "    setup['checkpoint_dir'], f\"{model['checkpoint']}.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop experiment\n",
    "It is very important to finish experiment after execution to free unused resources and to avoid unfinished statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "neptune": {
   "notebookId": "f8f1afa6-4ee7-427d-917e-9a28516e4fb4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
