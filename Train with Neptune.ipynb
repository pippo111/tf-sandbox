{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.dataset import get_loader, calculate_hash\n",
    "from networks.model import MyModel\n",
    "from utils.neptune import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration from json file. Alternatively you can put your configuration here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     \"neptune\": {\n",
    "#         \"project_name\": \"inn/Hippocampus\"\n",
    "#     },\n",
    "#     \"setup\": {\n",
    "#         \"dataset_dir\": \"/home/paperspace/datasets/processed/hippocampus_coronal_mindboggle_176x256_inn\",\n",
    "#         \"checkpoint_dir\": \"output/models\",\n",
    "#         \"struct\": \"hippocampus\",\n",
    "#         \"epochs\": 100,\n",
    "#         \"batch_size\": 16,\n",
    "#         \"train_ds_limit\": None,\n",
    "#         \"valid_ds_limit\": None,\n",
    "#         \"input_shape\": [\n",
    "#             256,\n",
    "#             176\n",
    "#         ],\n",
    "#         \"augment\": True,\n",
    "#         \"seed\": 5\n",
    "#     },\n",
    "#     \"model\": {\n",
    "#             \"arch\": \"Unet\",\n",
    "#             \"filters\": 16,\n",
    "#             \"loss_fn\": \"boundary_gdl\",\n",
    "#             \"optimizer_fn\": \"RAdam\",\n",
    "#             \"checkpoint\": \"hippocampus_coronal_boundary_gdl_unet_aug_radam\"\n",
    "#     },\n",
    "#     \"tags\": ['hippocampus', 'coronal']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neptune.config.json', 'r') as cfg_file:\n",
    "    config = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = config['setup']\n",
    "model = config['model']\n",
    "tags = config['tags'] or []\n",
    "dataset_dir = setup['dataset_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(dataset_dir, 'train',\n",
    "                          augment=setup['augment'],\n",
    "                          shuffle=True,\n",
    "                          limit=setup['train_ds_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get validation dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = get_loader(dataset_dir, 'valid',\n",
    "                          limit=setup['valid_ds_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate training dataset md5 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hash = calculate_hash(dataset_dir, 'train', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate training dataset md5 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_hash = calculate_hash(dataset_dir, 'valid', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune.ai configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.init(config['neptune']['project_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune.ai experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab model hyperparameters\n",
    "You can save any parameter you like, just append it to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'arch': model['arch'],\n",
    "    'batch_size': setup['batch_size'],\n",
    "    'filters': model['filters'],\n",
    "    'loss_fn': model['loss_fn'],\n",
    "    'optimizer_fn': model['optimizer_fn'],\n",
    "    'data_augment': setup['augment'],\n",
    "    'seed': setup['seed'],\n",
    "    'train_data_version': train_hash,\n",
    "    'valid_data_version': valid_hash\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = neptune.create_experiment(name=setup['struct'], params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add experiment tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.append_tag(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Basically this is the place, where we integrate neptune.ai with our codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyModel(checkpoint_dir=setup['checkpoint_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.setup_model(\n",
    "    train_generator=train_loader,\n",
    "    valid_generator=valid_loader,\n",
    "    checkpoint=model['checkpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.create_model(arch=model['arch'],\n",
    "                      optimizer_fn=model['optimizer_fn'],\n",
    "                      loss_fn=model['loss_fn'],\n",
    "                      n_filters=model['filters'],\n",
    "                      input_shape=tuple(setup['input_shape']),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neptune Callback for training\n",
    "We are using Tensorflow 2.0 with Keras helpers, so we can make use of Callbacks to save monitored metrics during the training. Each epoch restult metrics will be saved as chart log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.start_train(epochs=setup['epochs'], custom_callbacks=[\n",
    "    NeptuneMonitor(experiment=experiment, evaluation=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.load_model(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neptune Callback for evaluation\n",
    "Similarily to training we are using callback to save metrics. This time we are doing it for model evaluation, so only final metrics will be saved, without epoch by epoch chart log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.start_evaluate(custom_callbacks=[\n",
    "    NeptuneMonitor(experiment=experiment, evaluation=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload saved model\n",
    "After training we are sending best saved model checkpoint, as specified in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_artifact(os.path.join(\n",
    "    setup['checkpoint_dir'], f\"{model['checkpoint']}.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop experiment\n",
    "It is very important to finish experiment after execution to free unused resources and to avoid unfinished statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "neptune": {
   "notebookId": "f8f1afa6-4ee7-427d-917e-9a28516e4fb4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
